üß† Sistema Experimental RAG: An√°lisis del Framework REFRAG

Este proyecto implementa un sistema de Retrieval-Augmented Generation (RAG) dise√±ado para analizar documentos t√©cnicos complejos (espec√≠ficamente el paper "REFRAG: Rethinking RAG based Decoding" de Meta) y evaluar diferentes estrategias de recuperaci√≥n de informaci√≥n.

El objetivo principal es comparar emp√≠ricamente c√≥mo diferentes m√©todos de recuperaci√≥n (Keyword, Sem√°ntico e H√≠brido) impactan en la capacidad de un LLM para responder preguntas de opci√≥n m√∫ltiple con alta precisi√≥n.

üöÄ Caracter√≠sticas

Ingesta de Documentos: Procesamiento de PDFs t√©cnicos utilizando PyPDFLoader y RecursiveCharacterTextSplitter para una segmentaci√≥n inteligente.

Vector Store: Implementaci√≥n persistente con ChromaDB.

Modelos:

LLM: Google Gemini 1.5 Flash (v√≠a langchain-google-genai).

Embeddings: HuggingFace all-MiniLM-L6-v2.

Arquitectura Modular: Soporte para 4 pipelines de evaluaci√≥n distintos:

(A) Baseline: LLM sin contexto (Zero-shot).

(B) BM25: B√∫squeda basada en palabras clave (Keyword Search).

(C) Dense Retrieval: B√∫squeda sem√°ntica por similitud vectorial.

(D) Hybrid RAG: Ensemble Retriever (BM25 + Dense) con pesos ajustables.

Evaluaci√≥n Automatizada: Sistema de evaluaci√≥n que compara las predicciones contra un ground truth en formato JSON, midiendo precisi√≥n y latencia.

üõ†Ô∏è Requisitos Previos

Python 3.11+

Conda (Recomendado para la gesti√≥n de entornos)

Una API Key de Google AI Studio (para usar Gemini).

üì¶ Instalaci√≥n

Clona el repositorio:

git clone [https://github.com/tu-usuario/tu-repositorio.git](https://github.com/tu-usuario/tu-repositorio.git)
cd tu-repositorio


Configura el entorno:
Hemos preparado un archivo environment.yml para una instalaci√≥n limpia y compatible multiplataforma.

conda env create -f environment.yml
conda activate langchain_env


Variables de Entorno:
Crea un archivo .env en la ra√≠z del proyecto y a√±ade tu clave API:

GOOGLE_API_KEY=tu_clave_api_aqui


‚öôÔ∏è Estructura del Proyecto

‚îú‚îÄ‚îÄ chroma_db/                  # Base de datos vectorial (se genera autom√°ticamente)
‚îú‚îÄ‚îÄ rag_system.py               # Script principal (L√≥gica RAG y Evaluaci√≥n)
‚îú‚îÄ‚îÄ Modelizaci√≥nEmpresaUCMData.json  # Dataset de preguntas y respuestas
‚îú‚îÄ‚îÄ 2509.01092v2.pdf            # Paper de investigaci√≥n (Input)
‚îú‚îÄ‚îÄ environment.yml             # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md                   # Documentaci√≥n


‚ñ∂Ô∏è Uso

El script principal gestiona tanto la ingesta de documentos como la evaluaci√≥n.

Ejecutar la evaluaci√≥n:
Por defecto, el script est√° configurado para evaluar el pipeline H√≠brido.

python rag_system.py


Cambiar de Estrategia:
Para probar otros m√©todos (BM25, Dense, Baseline), edita las l√≠neas finales de rag_system.py:

# En el bloque if __name__ == "__main__":

# Para usar BM25:
chain = rag_manager.get_bm25_pipeline()
score, _ = evaluator.evaluate_pipeline(chain, "BM25 RAG")

# Para usar Dense Retrieval:
# chain = rag_manager.get_dense_pipeline()


üìä Metodolog√≠a de Evaluaci√≥n

El sistema utiliza un conjunto de datos (Modelizaci√≥nEmpresaUCMData.json) que contiene preguntas dif√≠ciles de opci√≥n m√∫ltiple sobre el paper. El evaluador:

Recupera el contexto relevante (o nada, en el caso del Baseline).

Construye un prompt con instrucciones estrictas.

Solicita al LLM la respuesta y la cita de la fuente.

Compara la respuesta (A, B, C, D) con la correcta y calcula el Accuracy.

üìö Tecnolog√≠as Utilizadas

LangChain v0.2 - Orquestaci√≥n de LLMs.

Chroma - Base de datos vectorial open-source.

Google Gemini API - Modelo Generativo.

HuggingFace - Modelos de Embeddings.

Rank-BM25 - Algoritmo de ranking probabil√≠stico.

üìÑ Referencia

El documento analizado en este proyecto es:

REFRAG: Rethinking RAG based Decoding (Meta SuperIntelligence Labs).

Hecho con ‚ù§Ô∏è usando Python y LangChain.
